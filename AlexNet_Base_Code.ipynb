{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet_Base_Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAM8-msW63Mn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPool2D, AveragePooling2D\n",
        "from sklearn.metrics import classification_report\n",
        "import keras.optimizers\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics \n",
        "from matplotlib import pyplot as plt\n",
        "from keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ur_uRJI7Tyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlvKpHmBQ7Mj",
        "colab_type": "text"
      },
      "source": [
        "Perpare data frame of Feature and Label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU-MWLbv7UQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = \"/content/drive/My Drive/498L Project/data/\"\n",
        "\n",
        "SPECIES_LIST = [\"Parus major\", \"Phylloscopus collybita\", \"Baeolophus bicolor\", \"Melospiza melodia\", \"Cardinalis cardinalis\", \"Hirundo rustica\", \"Zenaida macroura\",\n",
        "                \"Spinus tristis\", \"Icterus galbula\", \"Sturnella magna\", \"Thryothorus ludovicianus\", \"Passer domesticus\", \"Poecile atricapillus\", \n",
        "                \"Turdus migratorius\", \"Cyanistes caeruleus\",\"Loxia curvirostra\", \"Passer montanus\", \"Sylvia atricapilla\", \"Sylvia communis\"]\n",
        "\n",
        "df = pd.DataFrame(columns=['Feature', 'Class_Label'])\n",
        "for j in range(0,len(SPECIES_LIST)):\n",
        "  features = []\n",
        "  species = SPECIES_LIST[j]\n",
        "  tensor_file_loc = DATA_DIR + species + \"/MFCC Tensor/feature_tensor.p\"\n",
        "  tensor = pickle.load( open( tensor_file_loc, \"rb\" ) )\n",
        "  length = len(tensor)\n",
        "  for i in range(0,length):\n",
        "    row = [tensor[i], species]\n",
        "    df.loc[len(df)] = row"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh8u6FBvRMv5",
        "colab_type": "text"
      },
      "source": [
        "Doing one hot encoding and splitting to train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmcBhV0XRSS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.array(df.Feature.tolist())\n",
        "y = np.array(df.Class_Label.tolist())\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y)) \n",
        "x_training, x_test, y_training, y_test = train_test_split(X, yy, test_size=0.15, random_state = 42)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_training, y_training, test_size=0.1, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt-arnk0SAxa",
        "colab_type": "text"
      },
      "source": [
        "Building the Model (LeNet-5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W042BG4cSI55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_rows = 20\n",
        "num_columns = 1500\n",
        "num_channels = 1\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)\n",
        "x_val = x_val.reshape(x_val.shape[0], num_rows, num_columns, num_channels)\n",
        "x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)\n",
        "\n",
        "num_labels = yy.shape[1]\n",
        "stride = 2\n",
        "kernal = 2\n",
        "# Construct model \n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=kernal, input_shape=(num_rows, num_columns, num_channels)))#, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=(stride,stride)))\n",
        "#model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=kernal, activation='relu'))#,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=(stride,stride)))\n",
        "#model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=kernal, activation='relu'))#,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(Conv2D(filters=256, kernel_size=kernal, activation='relu'))\n",
        "model.add(Conv2D(filters=256, kernel_size=kernal, activation='relu'))\n",
        "\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(GlobalMaxPool2D())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "#model.add(Dropout(0.1))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(num_labels, activation='softmax'))#,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eaj9VTVAS3VY",
        "colab_type": "text"
      },
      "source": [
        "Train Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS6tyI2cUOpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "opt = keras.optimizers.Adam(learning_rate=0.005)\n",
        "#opt = keras.optimizers.SGD(lr=0.015,momentum=0.5)\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n",
        "\n",
        "num_epochs = 150\n",
        "num_batch_size = 200\n",
        "history = model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_val, y_val), verbose=1,shuffle=True)\n",
        "\n",
        "# Calculate accuracy \n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "accuracy = 100*score[1]\n",
        "\n",
        "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
        "y_pred = model.predict_classes(x_test)\n",
        "print(classification_report(Y_test, y_pred))\n",
        "\n",
        "print(\"Overall Accuracy: %.4f%%\" % accuracy) \n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoevxL3ZgpCr",
        "colab_type": "text"
      },
      "source": [
        "Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAxm_aFhgqZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"AlexNet_Base_Model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"AlexNet_Base_Model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}